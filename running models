2170447
2172016



We want to call a shell script to run our model when we are working on DTU cluster 

We want to run our model directly from python when we are working on laptops 
 

We want a very verbose logging system, as we will run many different models, 
and thus it can easy be difficult to know when what happend

Input to shell files:
    None - All generated 

shell/train.sh  -> 
    (error file, out file), 
    (model archictectures), 
    (hyper parameter settings), 
    (epoch / different losses),
    (some training images for visualization)
shell/test.sh   -> 
    (error file, out file), 
    (model archictectures tested), 
    (hyper parameter settings used), 
    (different losses),
    (some test images for visualization)

Input to python files:
    Some ID for grouping 

train.py  -> 
    (model archictectures), 
    (hyper parameter settings), 
    (epoch / different losses),
    (some training images for visualization)
test.py   -> 
    (model archictectures tested), 
    (hyper parameter settings used), 
    (different losses),
    (some test images for visualization)



Notes 
You can use Multi-GPU training by setting --gpu_ids (e.g., --gpu_ids 0,1,2,3 for the first four GPUs on your machine.) 
To fully utilize all the GPUs, you need to increase your batch size. Try --batch_size 4, --batch_size 16, or even a larger batch_size. 
Each GPU will process batch_size/#GPUs images. T
he optimal batch size depends on the number of GPUs you have, GPU memory per GPU, and the resolution of your training images.

Noise z 
The current pix2pix/CycleGAN model does not take z as input. 
In both pix2pix and CycleGAN, we tried to add z to the generator: e.g., adding z to a latent state, concatenating with a latent state, applying dropout, etc., 
but often found the output did not vary significantly as a function of z. 
Conditional GANs do not need noise as long as the input is sufficiently complex so that the input can kind of play the role of noise. 
Without noise, the mapping is deterministic.

Things we need to test:
 - Continue to train model 


Things we want to try: 
 - Add intermidiate layers 
 - Pixelshuffle 3 and 2 
 - Dropout 
 - (Instance vs Batch normalizeation)
 - 

Things we need to do 
 - Write report 
 - Implement core ml model in app

Take things of when done and stored safely



Currently running 
 - 06123439 (First 24h) (GAN)
    - 


Tunings: 
- Ratio on Generator (100, 50, 20, 10)
- Patchdiscriminator vs discrimiator 
- Batch size (1, 8 16)
- Fine tunin epocs 
- Learning rate



